{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T09:41:11.715209Z",
     "start_time": "2025-11-27T09:41:11.691289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torchmetrics\n",
    "import wandb"
   ],
   "id": "1c1e386f69493cf8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T09:41:11.772960Z",
     "start_time": "2025-11-27T09:41:11.752439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SignDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"dataset\", batch_size: int = 16):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Dataset in folder structure: dataset/class_name/*.jpg\n",
    "        self.dataset = datasets.ImageFolder(self.data_dir, transform=self.transform)\n",
    "\n",
    "        # 80/20 split\n",
    "        train_size = int(0.8 * len(self.dataset))\n",
    "        val_size = len(self.dataset) - train_size\n",
    "\n",
    "        self.train_set, self.val_set = torch.utils.data.random_split(\n",
    "            self.dataset, [train_size, val_size]\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size)"
   ],
   "id": "a895c2261740a0bc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-27T09:41:11.826102Z",
     "start_time": "2025-11-27T09:41:11.801385Z"
    }
   },
   "source": [
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class TrafficSignCNN(pl.LightningModule):\n",
    "    def __init__(self, class_names, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.class_names = class_names\n",
    "        self.num_classes = len(class_names)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 64), nn.ReLU(),\n",
    "            nn.Linear(64, self.num_classes)\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # --- METRICS ---\n",
    "        # Initialize metrics for easy calculation\n",
    "        self.f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.confmat = MulticlassConfusionMatrix(num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "        # Update running metrics\n",
    "        self.f1.update(preds, y)\n",
    "        self.confmat.update(preds, y)\n",
    "        self.accuracy.update(preds, y)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # 1. Compute and Log F1\n",
    "        f1_score = self.f1.compute()\n",
    "        self.log(\"val_f1\", f1_score, prog_bar=True)\n",
    "\n",
    "        # 2. Plot and Log Confusion Matrix\n",
    "        # .plot() returns a Matplotlib Figure and Axis\n",
    "        fig, ax = self.confmat.plot(labels=self.class_names)\n",
    "\n",
    "        # Log the figure to WandB as an image\n",
    "        if self.logger:\n",
    "            self.logger.experiment.log({\n",
    "                \"confusion_matrix\": wandb.Image(fig),\n",
    "                \"global_step\": self.global_step\n",
    "            })\n",
    "\n",
    "        # Close the figure to free memory\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.close(fig)\n",
    "\n",
    "        # 3. Reset metrics for the next epoch\n",
    "        self.f1.reset()\n",
    "        self.confmat.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T09:41:25.887336Z",
     "start_time": "2025-11-27T09:41:11.846013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb_logger = WandbLogger(project=\"sign-cnn\")\n",
    "\n",
    "data = SignDataModule(data_dir=\"C:/Users/robbe/PycharmProjects/DAI_Autonomous_Vehicles/Data/traffic_signs\", batch_size=16)\n",
    "model = TrafficSignCNN(class_names=[\"90\", \"60\", \"30\", \"stop\"])\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"auto\",\n",
    "    logger=wandb_logger,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, data)"
   ],
   "id": "78f631fcf59b2f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\robbe\\.conda\\envs\\DataScienceEnv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:658: Checkpoint directory .\\sign-cnn\\ww24mik2\\checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type                      | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | model    | Sequential                | 105 K  | train\n",
      "1 | loss_fn  | CrossEntropyLoss          | 0      | train\n",
      "2 | f1       | MulticlassF1Score         | 0      | train\n",
      "3 | accuracy | MulticlassAccuracy        | 0      | train\n",
      "4 | confmat  | MulticlassConfusionMatrix | 0      | train\n",
      "---------------------------------------------------------------\n",
      "105 K     Trainable params\n",
      "0         Non-trainable params\n",
      "105 K     Total params\n",
      "0.422     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robbe\\.conda\\envs\\DataScienceEnv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\robbe\\.conda\\envs\\DataScienceEnv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 25.62it/s, v_num=mik2, train_loss_step=1.630]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 58.94it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 60.51it/s]\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 32.92it/s, v_num=mik2, train_loss_step=1.270, val_loss=1.190, val_f1=0.161, train_loss_epoch=1.290]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 63.22it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 62.47it/s]\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.73it/s, v_num=mik2, train_loss_step=0.744, val_loss=1.050, val_f1=0.161, train_loss_epoch=1.040]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 61.16it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 66.34it/s]\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.83it/s, v_num=mik2, train_loss_step=0.614, val_loss=0.849, val_f1=0.435, train_loss_epoch=0.920]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 68.55it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 69.46it/s]\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.35it/s, v_num=mik2, train_loss_step=0.577, val_loss=0.688, val_f1=0.435, train_loss_epoch=0.792]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 59.54it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 55.15it/s]\n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 31.65it/s, v_num=mik2, train_loss_step=0.422, val_loss=0.563, val_f1=0.952, train_loss_epoch=0.697]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 55.27it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 58.21it/s]\n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.51it/s, v_num=mik2, train_loss_step=0.419, val_loss=0.475, val_f1=0.952, train_loss_epoch=0.617]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 63.43it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 65.25it/s]\n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.09it/s, v_num=mik2, train_loss_step=0.317, val_loss=0.373, val_f1=0.952, train_loss_epoch=0.515]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 60.94it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 64.58it/s]\n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.42it/s, v_num=mik2, train_loss_step=0.216, val_loss=0.315, val_f1=1.000, train_loss_epoch=0.444]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 66.00it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 66.64it/s]\n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 34.44it/s, v_num=mik2, train_loss_step=0.312, val_loss=0.214, val_f1=0.952, train_loss_epoch=0.358]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 58.63it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 55.34it/s]\n",
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 34.49it/s, v_num=mik2, train_loss_step=0.112, val_loss=0.200, val_f1=1.000, train_loss_epoch=0.319]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 63.87it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 67.05it/s]\n",
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 34.35it/s, v_num=mik2, train_loss_step=0.0819, val_loss=0.128, val_f1=1.000, train_loss_epoch=0.231]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 62.53it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 62.01it/s]\n",
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 34.62it/s, v_num=mik2, train_loss_step=0.0724, val_loss=0.0934, val_f1=1.000, train_loss_epoch=0.169]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 60.49it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 61.51it/s]\n",
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 35.03it/s, v_num=mik2, train_loss_step=0.0275, val_loss=0.0969, val_f1=1.000, train_loss_epoch=0.138]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 61.37it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 59.49it/s]\n",
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 32.24it/s, v_num=mik2, train_loss_step=0.0419, val_loss=0.0681, val_f1=1.000, train_loss_epoch=0.101]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 59.56it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 59.38it/s]\n",
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.90it/s, v_num=mik2, train_loss_step=0.0528, val_loss=0.0475, val_f1=1.000, train_loss_epoch=0.0748]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 61.80it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 62.20it/s]\n",
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 29.84it/s, v_num=mik2, train_loss_step=0.0126, val_loss=0.0399, val_f1=1.000, train_loss_epoch=0.0529]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 60.34it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 62.25it/s]\n",
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 31.87it/s, v_num=mik2, train_loss_step=0.0469, val_loss=0.0286, val_f1=1.000, train_loss_epoch=0.0406]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 57.88it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 57.91it/s]\n",
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.63it/s, v_num=mik2, train_loss_step=0.0152, val_loss=0.0331, val_f1=1.000, train_loss_epoch=0.037] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 59.38it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 60.62it/s]\n",
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 33.46it/s, v_num=mik2, train_loss_step=0.00473, val_loss=0.0279, val_f1=1.000, train_loss_epoch=0.0276]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 58.94it/s]\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 58.24it/s]\n",
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11.95it/s, v_num=mik2, train_loss_step=0.00473, val_loss=0.022, val_f1=1.000, train_loss_epoch=0.0231] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11.57it/s, v_num=mik2, train_loss_step=0.00473, val_loss=0.022, val_f1=1.000, train_loss_epoch=0.0231]\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
