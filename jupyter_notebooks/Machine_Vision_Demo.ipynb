{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>You can see your computer specifications here </h2>",
   "id": "d760726f04432b9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!nvidia-smi",
   "id": "aecfd9e8b674b9a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ultralytics import YOLO\n",
    "import carla, cv2, time, numpy as np, atexit\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from simulation.python_3_8_20_scripts.shared_memory_utils import CarlaWrapper\n",
    "\n",
    "# Choose model\n",
    "model_type = \"yolo11n.pt\"\n",
    "model = YOLO(model_type) # Load a pretrained YOLO.. model\n",
    "\n",
    "# === 2) Geef hier je afbeeldingsmap op ===\n",
    "img_dir = Path(\"/tmp/pycharm_project_481/Data/Paar\")  # <-- pas dit aan\n",
    "\n",
    "# === 3) Verzamel alle afbeeldingspaden ===\n",
    "img_paths = sorted(img_dir.glob(\"*.jpg\")) + sorted(img_dir.glob(\"*.png\"))\n",
    "print(f\"Gevonden {len(img_paths)} afbeeldingen.\")\n",
    "\n"
   ],
   "id": "e5ee3d324b9064fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === 4) YOLO run op alle afbeeldingen (niet opslaan, niet showen) ===\n",
    "results = model(\n",
    "    source=[str(p) for p in img_paths],\n",
    "    conf=0.4,\n",
    "    save=False,\n",
    "    show=False\n",
    ")\n",
    "print(type(results[0]))\n",
    "\n",
    "# === 5) Toon alle detectieresultaten ===\n",
    "for i, result in enumerate(results):\n",
    "    res_img = result.plot()  # Tekent bounding boxes\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(res_img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Detectieresultaat afbeelding {i+1}: {img_paths[i].name}\")\n",
    "    plt.show()\n",
    "    print(type(res_img))"
   ],
   "id": "97ca4ca30c44dd51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>Section below is for live feed</h3>",
   "id": "ffd6833e7138e07b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --------------------------------------------------------------\n",
    "# Helper: convert CARLA image (BGRA) → RGB NumPy array\n",
    "# --------------------------------------------------------------\n",
    "def carla_image_to_rgb(image):\n",
    "    # Convert raw bytes into a NumPy array\n",
    "    arr = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    # Reshape to height × width × 4 (BGRA channels)\n",
    "    arr = arr.reshape((image.height, image.width, 4))\n",
    "    # Keep only the first 3 channels and flip BGR→RGB\n",
    "    return arr[:, :, :3][:, :, ::-1]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Connect to the CARLA simulator\n",
    "# --------------------------------------------------------------\n",
    "client = carla.Client(\"localhost\", 2000)   # connect to server\n",
    "client.set_timeout(10.0)\n",
    "world = client.get_world()                 # get current world\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Enable synchronous mode for stable frame rate\n",
    "# --------------------------------------------------------------\n",
    "settings = world.get_settings()\n",
    "if not settings.synchronous_mode:\n",
    "    settings.synchronous_mode = True\n",
    "    settings.fixed_delta_seconds = 1 / 20.0  # 20 FPS simulation step\n",
    "    world.apply_settings(settings)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Spawn the ego vehicle (Tesla Model 3) at the first spawn point\n",
    "# --------------------------------------------------------------\n",
    "blueprints = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "vehicle_bp = blueprints.find(\"vehicle.tesla.model3\")\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_points[0])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Attach an RGB camera sensor to the vehicle\n",
    "# --------------------------------------------------------------\n",
    "rgb_bp = blueprints.find(\"sensor.camera.rgb\")\n",
    "rgb_bp.set_attribute(\"image_size_x\", \"1280\")   # width in pixels\n",
    "rgb_bp.set_attribute(\"image_size_y\", \"720\")    # height in pixels\n",
    "rgb_bp.set_attribute(\"fov\", \"90\")              # horizontal field of view\n",
    "camera_transform = carla.Transform(\n",
    "    carla.Location(x=0.3, z=1.6),              # position relative to car\n",
    "    carla.Rotation(pitch=-6)                   # slightly facing downward\n",
    ")\n",
    "rgb_cam = world.spawn_actor(rgb_bp, camera_transform, attach_to=vehicle)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Cleanup routine (automatically called on exit)\n",
    "# Ensures all actors are properly destroyed\n",
    "# --------------------------------------------------------------\n",
    "def cleanup():\n",
    "    try:\n",
    "        rgb_cam.stop()\n",
    "        vehicle.set_autopilot(False)\n",
    "        time.sleep(0.1)\n",
    "        rgb_cam.destroy()\n",
    "        vehicle.destroy()\n",
    "        settings.synchronous_mode = False\n",
    "        world.apply_settings(settings)\n",
    "        cv2.destroyAllWindows()\n",
    "    except:\n",
    "        pass\n",
    "atexit.register(cleanup)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Listen to camera frames asynchronously\n",
    "# The last received frame is stored in the \"frame\" dict\n",
    "# --------------------------------------------------------------\n",
    "frame = {\"img\": None}\n",
    "rgb_cam.listen(lambda img: frame.update(img=img))\n",
    "\n",
    "# Enable autopilot so the vehicle drives automatically\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "print(\"Running... (Press ESC to stop)\")\n",
    "# --------------------------------------------------------------\n",
    "# Main simulation loop\n",
    "# --------------------------------------------------------------\n",
    "while True:\n",
    "    world.tick()                    # advance the simulation one frame\n",
    "    if frame[\"img\"] is None:        # skip until the first image arrives\n",
    "        continue\n",
    "\n",
    "    # Convert CARLA image to a normal RGB NumPy array\n",
    "    rgb = carla_image_to_rgb(frame[\"img\"])\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Run YOLO detection on the current RGB frame\n",
    "    # Only draw bounding boxes (no class labels yet)\n",
    "    # ----------------------------------------------------------\n",
    "    res = model.predict(rgb, verbose=False, conf=0.25)[0]\n",
    "\n",
    "    if res.boxes is not None and len(res.boxes) > 0:\n",
    "        # Iterate over all detected boxes\n",
    "        for (x1, y1, x2, y2) in res.boxes.xyxy.cpu().numpy():\n",
    "            # Draw green rectangle around each detected object\n",
    "            p1 = (int(x1), int(y1))\n",
    "            p2 = (int(x2), int(y2))\n",
    "            cv2.rectangle(rgb, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the annotated image in a live OpenCV window\n",
    "    cv2.imshow(\"Detection only\", cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Exit loop when ESC key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break"
   ],
   "id": "f25b10f3d27b64f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>Training the YOLOv11 </h3>",
   "id": "6b3c861e3734c83a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c0ee7e85f58e849d"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
